# Azure Data Lake Storage Gen2 Configuration
azure:
  data_lake:
    account_name: "${ADLS_ACCOUNT_NAME}"
    account_key: "${ADLS_ACCOUNT_KEY}"
    container_name: "${ADLS_CONTAINER_NAME:-spotify-data}"
    
    # File system structure
    paths:
      raw: "raw"
      bronze: "bronze" 
      silver: "silver"
      gold: "gold"
      
    # Data partitioning
    partitions:
      streaming_history: "year={year}/month={month}/day={day}"
      user_events: "date={date}/hour={hour}"
      
    # File formats
    formats:
      streaming_events: "parquet"
      batch_data: "delta"
      
  # Service Principal Authentication (recommended for production)
  service_principal:
    client_id: "${AZURE_CLIENT_ID}"
    client_secret: "${AZURE_CLIENT_SECRET}"
    tenant_id: "${AZURE_TENANT_ID}"
    
  # Databricks integration
  databricks:
    workspace_url: "${DATABRICKS_WORKSPACE_URL}"
    access_token: "${DATABRICKS_ACCESS_TOKEN}"
    cluster_id: "${DATABRICKS_CLUSTER_ID}"
    
# Connection strings
connection_strings:
  adls: "abfss://${ADLS_CONTAINER_NAME}@${ADLS_ACCOUNT_NAME}.dfs.core.windows.net/"
  databricks_jdbc: "jdbc:databricks://${DATABRICKS_WORKSPACE_URL}:443/default;transportMode=http;ssl=1;AuthMech=3;httpPath=/sql/1.0/warehouses/${DATABRICKS_WAREHOUSE_ID};ConnCatalog=hive_metastore"