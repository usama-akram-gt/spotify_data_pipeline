# Local Development Environment Variables
# Copy this to .env for local development

# Database (Local PostgreSQL)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres
DB_PASSWORD=

# Kafka (Local)
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_TOPIC_STREAMING=streaming-events

# Airflow (Local)
AIRFLOW_UID=50000
AIRFLOW_GID=0
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/airflow
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
AIRFLOW__CORE__LOAD_EXAMPLES=false
AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth

# Local storage paths
DATA_PATH=./data
RAW_DATA_PATH=./data/raw
PROCESSED_DATA_PATH=./data/processed
ANALYTICS_DATA_PATH=./data/analytics

# Databricks Community Edition (Optional - for testing only)
# Sign up at https://community.cloud.databricks.com/
DATABRICKS_WORKSPACE_URL=community.cloud.databricks.com
DATABRICKS_ACCESS_TOKEN=your_community_token_here
DATABRICKS_WAREHOUSE_ID=your_warehouse_id_here

# Environment
ENVIRONMENT=local
PROJECT_NAME=spotify-pipeline
OWNER=local-dev